{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e942951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import calendar\n",
    "import unicodedata\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba00663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/Pb_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/As_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/B(a)P_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/Cd_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/PM10_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/Ni_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/PM2.5_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/Pb_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/Cd_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/As_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/PM2.5_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/Ni_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/B(a)P_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/PM10_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/As_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/B(a)P_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/PM10_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/Cd_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/Ni_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/Pb_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/PM25_DD_2016.xlsx\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/Pb_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/Ni_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/BaP_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/Cd_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/PM2.5_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/As_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/PM10_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/PM10_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/B(a)P_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/PM2.5_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/As_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/Pb_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/Cd_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/Ni_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/B(a)P_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/Cd_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/Ni_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/PM2.5_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/As_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/PM10_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/Pb_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/PM25_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/As_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/Cd_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/PM10_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/C6H6_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/Pb_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/BaP_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/Ni_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/B(a)P_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/Pb_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/PM10_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/PM2.5_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/Ni_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/Cd_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/As_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/C6H6_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/PM25_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/BaP_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/As_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/Cd_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/PM10_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/Ni_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/Pb_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/Ni_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/PM2.5_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/B(a)P_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/Cd_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/PM10_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/C6H6_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/Pb_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/As_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/C6H6_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/PM2.5_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/PM10_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/As_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/Pb_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/Ni_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/Cd_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/B(a)P_DD_2023.csv\n",
      "Archivo combinado guardado en /workspaces/Finarosalina_proyecto_final/data/air_data.csv\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/workspaces/Finarosalina_proyecto_final/data/raw\"\n",
    "dfs = []\n",
    "\n",
    "# Función para extraer año de la carpeta (ejemplo: \"2013_Datos_diarios\" -> 2013)\n",
    "def extraer_anno(nombre_carpeta):\n",
    "    import re\n",
    "    match = re.search(r'(\\d{4})', nombre_carpeta)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# 1. Leer Excel (2014-2016)\n",
    "for year_folder in ['2014_datos_Diarios', '2015_datos_Diarios', '2016_datos_Diarios']:\n",
    "    folder_path = os.path.join(base_path, \"2014_2016_Datos_diarios_excel\", year_folder)\n",
    "    anno = extraer_anno(year_folder)\n",
    "    excel_files = glob(os.path.join(folder_path, \"*.xlsx\")) + glob(os.path.join(folder_path, \"*.xls\"))\n",
    "    for file in excel_files:\n",
    "        print(f\"Leyendo Excel: {file}\")\n",
    "        df = pd.read_excel(file)\n",
    "        if 'ANNO' not in df.columns:\n",
    "            df['ANNO'] = anno\n",
    "        dfs.append(df)\n",
    "\n",
    "# 2. Leer CSVs (otros años)\n",
    "years_with_csv = [\n",
    "    \"2013_Datos_diarios\", \"2017_Datos_diarios\", \"2018_Datos_diarios\",\n",
    "    \"2019_datos_diarios\", \"2020_Datos_diarios\", \"2021_Datos_diarios\",\n",
    "    \"2022_Datos_diarios\", \"2023_Datos_diarios\"\n",
    "]\n",
    "\n",
    "for year_folder in years_with_csv:\n",
    "    folder_path = os.path.join(base_path, year_folder)\n",
    "    anno = extraer_anno(year_folder)\n",
    "    csv_files = glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    for file in csv_files:\n",
    "        print(f\"Leyendo CSV: {file}\")\n",
    "        df = pd.read_csv(file, sep=';', encoding='utf-8')\n",
    "        if 'ANNO' not in df.columns:\n",
    "            df['ANNO'] = anno\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenar y guardar\n",
    "air_data = pd.concat(dfs, ignore_index=True)\n",
    "output_path = \"/workspaces/Finarosalina_proyecto_final/data/air_data.csv\"\n",
    "air_data.to_csv(output_path, index=False, sep=';')\n",
    "print(f\"Archivo combinado guardado en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fe4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspaces/Finarosalina_proyecto_final/data/processed/air_data.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5813daa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>MAGNITUD</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>D01</th>\n",
       "      <th>D02</th>\n",
       "      <th>D03</th>\n",
       "      <th>...</th>\n",
       "      <th>D22</th>\n",
       "      <th>D23</th>\n",
       "      <th>D24</th>\n",
       "      <th>D25</th>\n",
       "      <th>D26</th>\n",
       "      <th>D27</th>\n",
       "      <th>D28</th>\n",
       "      <th>D29</th>\n",
       "      <th>D30</th>\n",
       "      <th>D31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD PUNTO_MUESTREO  ANNO  MES  D01  \\\n",
       "0          3          9         6        19  03009006_19_M  2014    1  NaN   \n",
       "1          3          9         6        19  03009006_19_M  2014    2  NaN   \n",
       "2          3          9         6        19  03009006_19_M  2014    3  0.0   \n",
       "3          3          9         6        19  03009006_19_M  2014    4  NaN   \n",
       "4          3          9         6        19  03009006_19_M  2014    5  NaN   \n",
       "\n",
       "   D02  D03  ...  D22  D23  D24  D25  D26  D27  D28  D29  D30  D31  \n",
       "0  NaN  NaN  ...  0.0  NaN  NaN  NaN  0.0  NaN  NaN  0.0  NaN  0.0  \n",
       "1  NaN  NaN  ...  0.0  NaN  0.0  NaN  NaN  0.0  NaN  NaN  NaN  NaN  \n",
       "2  NaN  0.0  ...  0.0  NaN  0.0  NaN  NaN  0.0  NaN  0.0  NaN  0.0  \n",
       "3  NaN  0.0  ...  NaN  NaN  0.0  NaN  0.0  NaN  NaN  0.0  NaN  NaN  \n",
       "4  0.0  0.0  ...  0.0  0.0  0.0  0.0  NaN  0.0  NaN  0.0  NaN  0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7468e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123569, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c9c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROVINCIA             0\n",
      "MUNICIPIO             0\n",
      "ESTACION              0\n",
      "MAGNITUD              0\n",
      "PUNTO_MUESTREO        0\n",
      "ANNO                  0\n",
      "MES                   0\n",
      "D01               69227\n",
      "D02               67484\n",
      "D03               66910\n",
      "D04               67538\n",
      "D05               67838\n",
      "D06               68581\n",
      "D07               66855\n",
      "D08               67692\n",
      "D09               66312\n",
      "D10               66078\n",
      "D11               66564\n",
      "D12               66024\n",
      "D13               65844\n",
      "D14               65580\n",
      "D15               65176\n",
      "D16               66060\n",
      "D17               66210\n",
      "D18               66726\n",
      "D19               65876\n",
      "D20               66015\n",
      "D21               65737\n",
      "D22               66692\n",
      "D23               66768\n",
      "D24               67866\n",
      "D25               67295\n",
      "D26               67259\n",
      "D27               67150\n",
      "D28               67653\n",
      "D29               71966\n",
      "D30               72915\n",
      "D31               92599\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_por_columna = df.isna().sum()\n",
    "print(nan_por_columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc1f1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'MAGNITUD', 'PUNTO_MUESTREO',\n",
       "       'ANNO', 'MES', 'D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08',\n",
       "       'D09', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'D16', 'D17', 'D18',\n",
       "       'D19', 'D20', 'D21', 'D22', 'D23', 'D24', 'D25', 'D26', 'D27', 'D28',\n",
       "       'D29', 'D30', 'D31'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31cafb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en columnas ANNO, MES, DIA antes de crear la columna FECHA:\n",
      "ANNO    0\n",
      "MES     0\n",
      "DIA     0\n",
      "dtype: int64\n",
      "   PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD PUNTO_MUESTREO  ANNO  MES  DIA  \\\n",
      "0          3          9         6        19  03009006_19_M  2014    1    1   \n",
      "1          3          9         6        19  03009006_19_M  2014    2    1   \n",
      "2          3          9         6        19  03009006_19_M  2014    3    1   \n",
      "3          3          9         6        19  03009006_19_M  2014    4    1   \n",
      "4          3          9         6        19  03009006_19_M  2014    5    1   \n",
      "\n",
      "   VALOR      FECHA  \n",
      "0    NaN 2014-01-01  \n",
      "1    NaN 2014-02-01  \n",
      "2    0.0 2014-03-01  \n",
      "3    NaN 2014-04-01  \n",
      "4    NaN 2014-05-01  \n"
     ]
    }
   ],
   "source": [
    "# Función para validar la fecha\n",
    "def es_fecha_valida(anno, mes, dia):\n",
    "    if mes < 1 or mes > 12 or dia < 1:\n",
    "        return False\n",
    "    ultimo_dia = calendar.monthrange(anno, mes)[1]  # Obtiene el último día del mes\n",
    "    return dia <= ultimo_dia  # Comprueba si el día es válido\n",
    "\n",
    "# Primero, seleccionamos las columnas de días\n",
    "dias_columnas = [f'D{i:02d}' for i in range(1, 32)]  # ['D01', 'D02', ..., 'D31']\n",
    "\n",
    "# Aplanamos el DataFrame para que cada fila represente un día\n",
    "df = df.melt(id_vars=['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'MAGNITUD', 'PUNTO_MUESTREO', 'ANNO', 'MES'],\n",
    "             value_vars=dias_columnas,\n",
    "             var_name='DIA', value_name='VALOR')\n",
    "\n",
    "# Extraer el número de día de la columna 'DIA'\n",
    "df['DIA'] = df['DIA'].str.extract(r'D(\\d+)').astype(int)\n",
    "\n",
    "# Aplicamos la validación de la fecha para cada fila\n",
    "df['fecha_valida'] = df.apply(lambda row: es_fecha_valida(row['ANNO'], row['MES'], row['DIA']), axis=1)\n",
    "\n",
    "# Filtramos las filas que tengan fecha válida\n",
    "df = df[df['fecha_valida']]\n",
    "\n",
    "# Verificar si alguna columna tiene valores nulos o vacíos antes de convertir a fecha\n",
    "print(\"Valores nulos en columnas ANNO, MES, DIA antes de crear la columna FECHA:\")\n",
    "print(df[['ANNO', 'MES', 'DIA']].isna().sum())\n",
    "\n",
    "# Filtrar filas con valores nulos en ANNO, MES o DIA\n",
    "df = df.dropna(subset=['ANNO', 'MES', 'DIA'])\n",
    "\n",
    "# Crear la columna FECHA usando las columnas 'ANNO', 'MES', y 'DIA'\n",
    "df['FECHA'] = pd.to_datetime(df[['ANNO', 'MES', 'DIA']].astype(str).agg('-'.join, axis=1))\n",
    "\n",
    "# Ya podemos eliminar la columna auxiliar 'fecha_valida'\n",
    "df.drop(columns=['fecha_valida'], inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame final\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "419f442f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3760021, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88ca12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# que sea string\n",
    "df['PUNTO_MUESTREO'] = df['PUNTO_MUESTREO'].astype(str)\n",
    "\n",
    "# Extraer la clave: primeros 5 dígitos (provincia + municipio)\n",
    "df['PUNTO_MUESTREO'] = df['PUNTO_MUESTREO'].astype(str)\n",
    "\n",
    "# Extraer la clave como los primeros 5 dígitos del campo\n",
    "df['CLAVE'] = df['PUNTO_MUESTREO'].str.extract(r'(\\d{5})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cca46b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "\n",
    "# === 1. Cargar diccionario de municipios desde Excel ===\n",
    "df_dic = pd.read_excel(\n",
    "    '/workspaces/Finarosalina_proyecto_final/data/raw/diccionario23.xlsx',\n",
    "    skiprows=1,  # Saltar primera fila de paja\n",
    "    dtype={'CPRO': str, 'CMUN': str}  # Asegurar lectura como texto\n",
    ")\n",
    "\n",
    "# Asegurar formato correcto de códigos\n",
    "df_dic['CPRO'] = df_dic['CPRO'].str.zfill(2)\n",
    "df_dic['CMUN'] = df_dic['CMUN'].str.zfill(3)\n",
    "df_dic['CLAVE'] = df_dic['CPRO'] + df_dic['CMUN']\n",
    "\n",
    "# Normalizar nombres para que no tengan tildes ni caracteres especiales\n",
    "df_dic['NOMBRE_NORMALIZADO'] = df_dic['NOMBRE '].apply(lambda x: unidecode.unidecode(str(x)).strip())\n",
    "\n",
    "# === 2. Diccionario de capitales de provincia ===\n",
    "capitales_mun_dict = {\n",
    "    '0159': 'Vitoria Gasteiz', '02003': 'Albacete', '0314': 'Alacant Alicante', '0413': 'Almeria', '0519': 'Avila',\n",
    "    '15': 'Badajoz', '0740': 'Palma', '19': 'Barcelona', '0959': 'Burgos', '37': 'Caceres',\n",
    "    '12': 'Cadiz', '1240': 'Castello de la Plana', '13': 'Ciudad Real', '14': 'Cordoba',\n",
    "    '15': 'Coruna', '16': 'Cuenca', '17': 'Girona', '18': 'Granada', '19': 'Guadalajara',\n",
    "    '20': 'San Sebastian', '21': 'Huelva', '22': 'Huesca', '23': 'Jaen', '24': 'Leon',\n",
    "    '25': 'Lleida', '26': 'Logrono', '27': 'Lugo', '28': 'Madrid', '29': 'Malaga',\n",
    "    '30': 'Murcia', '31': 'Pamplona', '32': 'Ourense', '33': 'Oviedo', '34': 'Palencia',\n",
    "    '35': 'Las Palmas', '36': 'Pontevedra', '37': 'Salamanca', '38': 'Santa Cruz de Tenerife',\n",
    "    '39': 'Santander', '40': 'Segovia', '41': 'Sevilla', '42': 'Soria', '43': 'Tarragona',\n",
    "    '44': 'Teruel', '45': 'Toledo', '46': 'Valencia', '47': 'Valladolid', '48': 'Bilbao',\n",
    "    '49': 'Zamora', '50': 'Zaragoza', '51': 'Ceuta', '52': 'Melilla'\n",
    "}\n",
    "\n",
    "# Crear diccionario final: claves válidas del Excel que estén en el dict de capitales\n",
    "diccionario_capitales = {\n",
    "    clave: capitales_mun_dict[clave]\n",
    "    for clave in df_dic['CLAVE']\n",
    "    if clave in capitales_mun_dict\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c04f6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_capitales = df[df['CLAVE'].isin(diccionario_capitales.keys())].copy()\n",
    "\n",
    "# Añadir nombre de la capital\n",
    "\n",
    "df['NOMBRE_CAPITAL'] = df['CLAVE'].map(diccionario_capitales)\n",
    "df_capitales = df[df['NOMBRE_CAPITAL'].notna()].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc3e7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capitales = df[df['PUNTO_MUESTREO'].str[:5].isin(diccionario_capitales.keys())].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89eebe3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16505, 12)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_capitales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bcdd506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df_capitales: (16505, 12)\n",
      "\n",
      "Valores nulos por columna:\n",
      "PROVINCIA             0\n",
      "MUNICIPIO             0\n",
      "ESTACION              0\n",
      "MAGNITUD              0\n",
      "PUNTO_MUESTREO        0\n",
      "ANNO                  0\n",
      "MES                   0\n",
      "DIA                   0\n",
      "VALOR             10347\n",
      "FECHA                 0\n",
      "CLAVE                 0\n",
      "NOMBRE_CAPITAL        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ver la forma (filas, columnas)\n",
    "print(\"Shape df_capitales:\", df_capitales.shape)\n",
    "\n",
    "# Cantidad de valores nulos por columna\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df_capitales.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d4ae7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>NOMBRE_CAPITAL</th>\n",
       "      <th>As</th>\n",
       "      <th>BaP</th>\n",
       "      <th>Cd</th>\n",
       "      <th>Ni</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>Pb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROVINCIA  MUNICIPIO  ESTACION  PUNTO_MUESTREO  ANNO  MES  DIA      FECHA  \\\n",
       "0          2          3         1  02003001_10_49  2017    1    1 2017-01-01   \n",
       "1          2          3         1  02003001_10_49  2017    1    2 2017-01-02   \n",
       "2          2          3         1  02003001_10_49  2017    1    3 2017-01-03   \n",
       "3          2          3         1  02003001_10_49  2017    1    6 2017-01-06   \n",
       "4          2          3         1  02003001_10_49  2017    1    7 2017-01-07   \n",
       "\n",
       "  NOMBRE_CAPITAL  As  BaP  Cd  Ni  PM10  PM2.5  Pb  \n",
       "0       Albacete NaN  NaN NaN NaN  27.0    NaN NaN  \n",
       "1       Albacete NaN  NaN NaN NaN  21.0    NaN NaN  \n",
       "2       Albacete NaN  NaN NaN NaN  32.0    NaN NaN  \n",
       "3       Albacete NaN  NaN NaN NaN  25.0    NaN NaN  \n",
       "4       Albacete NaN  NaN NaN NaN  24.0    NaN NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diccionario de nombres contaminantes\n",
    "magnitud_dict = {\n",
    "    9: 'PM2.5',\n",
    "    10: 'PM10',\n",
    "    17: 'As',\n",
    "    19: 'Pb',\n",
    "    27: 'BaP',\n",
    "    28: 'Cd',\n",
    "    62: 'Ni'\n",
    "}\n",
    "\n",
    "# Mapear nombre del contaminante\n",
    "df_capitales['MAGNITUD_NOMBRE'] = df_capitales['MAGNITUD'].map(magnitud_dict)\n",
    "\n",
    "# Filtrar filas que tienen valor y contaminante reconocido\n",
    "df_filtrado = df_capitales[\n",
    "    df_capitales['VALOR'].notnull() &\n",
    "    df_capitales['MAGNITUD_NOMBRE'].notnull()\n",
    "]\n",
    "\n",
    "# Pivotar para tener cada contaminante como columna\n",
    "df_contaminantes = df_filtrado.pivot_table(\n",
    "    index=['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'PUNTO_MUESTREO', 'ANNO', 'MES', 'DIA', 'FECHA', 'NOMBRE_CAPITAL'],\n",
    "    columns='MAGNITUD_NOMBRE',\n",
    "    values='VALOR',\n",
    "    aggfunc='first'  # O 'mean' si hay múltiples valores\n",
    ").reset_index()\n",
    "\n",
    "# Limpiar el nombre del índice de columnas creado por pivot_table\n",
    "df_contaminantes.columns.name = None\n",
    "\n",
    "df_contaminantes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8122ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la columna punto_muestreo contiene codigo provincia(2)+codigo municipio(3)+estacion(3)\n",
    "df_contaminantes = df_contaminantes.drop(columns=['PROVINCIA', 'MUNICIPIO', 'ESTACION'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1484710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>NOMBRE_CAPITAL</th>\n",
       "      <th>As</th>\n",
       "      <th>BaP</th>\n",
       "      <th>Cd</th>\n",
       "      <th>Ni</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>Pb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PUNTO_MUESTREO  ANNO  MES  DIA      FECHA NOMBRE_CAPITAL  As  BaP  Cd  Ni  \\\n",
       "0  02003001_10_49  2017    1    1 2017-01-01       Albacete NaN  NaN NaN NaN   \n",
       "1  02003001_10_49  2017    1    2 2017-01-02       Albacete NaN  NaN NaN NaN   \n",
       "2  02003001_10_49  2017    1    3 2017-01-03       Albacete NaN  NaN NaN NaN   \n",
       "3  02003001_10_49  2017    1    6 2017-01-06       Albacete NaN  NaN NaN NaN   \n",
       "4  02003001_10_49  2017    1    7 2017-01-07       Albacete NaN  NaN NaN NaN   \n",
       "\n",
       "   PM10  PM2.5  Pb  \n",
       "0  27.0    NaN NaN  \n",
       "1  21.0    NaN NaN  \n",
       "2  32.0    NaN NaN  \n",
       "3  25.0    NaN NaN  \n",
       "4  24.0    NaN NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contaminantes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f2a146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6158, 13)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contaminantes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41261afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CCAA                            NOMBRE_ZONA CODIGO_ZONA          TIPO  \\\n",
      "0  ANDALUCÍA  ZONA INDUSTRIAL DE BAHIA DE ALGECIRAS      ES0104          zona   \n",
      "1  ANDALUCÍA              ZONA INDUSTRIAL DE BAILEN      ES0108          zona   \n",
      "2  ANDALUCÍA                                CORDOBA      ES0111  aglomeracion   \n",
      "3  ANDALUCÍA          ZONA INDUSTRIAL DE CARBONERAS      ES0116          zona   \n",
      "4  ANDALUCÍA           GRANADA Y AREA METROPOLITANA      ES0118  aglomeracion   \n",
      "\n",
      "     AREA  POBLACION  SO2  SO2_E  NO2  NOX_V  ...  PM25   PB  C6H6   CO   O3  \\\n",
      "0  583.50     242508  1.0    NaN  1.0    NaN  ...   1.0  1.0   1.0  1.0  1.0   \n",
      "1  121.01      17498  1.0    NaN  1.0    NaN  ...   1.0  1.0   1.0  1.0  1.0   \n",
      "2  141.03     322071  1.0    NaN  1.0    NaN  ...   1.0  1.0   1.0  1.0  1.0   \n",
      "3  695.01      39641  1.0    NaN  1.0    NaN  ...   1.0  1.0   1.0  1.0  1.0   \n",
      "4  560.74     500735  1.0    NaN  1.0    NaN  ...   1.0  1.0   1.0  1.0  1.0   \n",
      "\n",
      "   'AS'   CD   NI  BAP  O3_V  \n",
      "0   1.0  1.0  1.0  1.0   1.0  \n",
      "1   1.0  1.0  1.0  1.0   NaN  \n",
      "2   1.0  1.0  1.0  1.0   1.0  \n",
      "3   1.0  1.0  1.0  1.0   1.0  \n",
      "4   1.0  1.0  1.0  1.0   1.0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Index(['CCAA', 'NOMBRE_ZONA', 'CODIGO_ZONA', 'TIPO', 'AREA', 'POBLACION',\n",
      "       'SO2', 'SO2_E', 'NO2', 'NOX_V', 'PM10', 'PM25', 'PB', 'C6H6', 'CO',\n",
      "       'O3', ''AS'', 'CD', 'NI', 'BAP', 'O3_V'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# https://www.miteco.gob.es/es/calidad-y-evaluacion-ambiental/temas/atmosfera-y-calidad-del-aire/evaluacion-y-datos-de-calidad-del-aire/datos.html\n",
    "# hemos encontrado un plan de muestreo segun el que no se tienen que medir todos los contaminantes en todas las zonas\n",
    "\n",
    "# 1. Cargar el plan de medición\n",
    "df_plan_medicion = pd.read_excel('/workspaces/Finarosalina_proyecto_final/data/raw/plan_medicion_2022_por_zona.xlsx')\n",
    "\n",
    "# 2. Ver las primeras filas para entender su estructura\n",
    "print(df_plan_medicion.head())\n",
    "\n",
    "# 3. Mostrar columnas para conocer las variables que miden (por ejemplo SO2, NO2, PM10...)\n",
    "print(df_plan_medicion.columns)\n",
    "\n",
    "# no podemos relacionarlo con nuestro data set pq no hay codigos unicos que lo hagan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af0e7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_ica(row):\n",
    "    # Umbrales\n",
    "    umbrales_bajos = {'As': 1, 'BaP': 0.1, 'Cd': 0.5, 'Ni': 1, 'PM10': 20, 'PM2.5': 10, 'Pb': 0.5}\n",
    "    umbrales_altos = {'As': 5, 'BaP': 0.5, 'Cd': 1.0, 'Ni': 5, 'PM10': 50, 'PM2.5': 25, 'Pb': 1.5}\n",
    "\n",
    "    calidad = 1  # Empezamos en buena calidad\n",
    "\n",
    "    for c in umbrales_bajos.keys():\n",
    "        valor = row.get(c, float('nan'))\n",
    "        if pd.isna(valor):\n",
    "            continue  # ignoramos valores NaN\n",
    "\n",
    "        if valor > umbrales_altos[c]:\n",
    "            return 3  # Mala calidad, primer umbral alto superado\n",
    "        elif valor > umbrales_bajos[c]:\n",
    "            calidad = max(calidad, 2)  # Calidad moderada si supera umbral bajo\n",
    "\n",
    "    return calidad\n",
    "\n",
    "# Aplicar al dataframe\n",
    "df_contaminantes['ICA'] = df_contaminantes.apply(calcular_ica, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c452001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>NOMBRE_CAPITAL</th>\n",
       "      <th>As</th>\n",
       "      <th>BaP</th>\n",
       "      <th>Cd</th>\n",
       "      <th>Ni</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>Pb</th>\n",
       "      <th>ICA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PUNTO_MUESTREO  ANNO  MES  DIA      FECHA NOMBRE_CAPITAL  As  BaP  Cd  Ni  \\\n",
       "0  02003001_10_49  2017    1    1 2017-01-01       Albacete NaN  NaN NaN NaN   \n",
       "1  02003001_10_49  2017    1    2 2017-01-02       Albacete NaN  NaN NaN NaN   \n",
       "2  02003001_10_49  2017    1    3 2017-01-03       Albacete NaN  NaN NaN NaN   \n",
       "3  02003001_10_49  2017    1    6 2017-01-06       Albacete NaN  NaN NaN NaN   \n",
       "4  02003001_10_49  2017    1    7 2017-01-07       Albacete NaN  NaN NaN NaN   \n",
       "\n",
       "   PM10  PM2.5  Pb  ICA  \n",
       "0  27.0    NaN NaN    2  \n",
       "1  21.0    NaN NaN    2  \n",
       "2  32.0    NaN NaN    2  \n",
       "3  25.0    NaN NaN    2  \n",
       "4  24.0    NaN NaN    2  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contaminantes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2507f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contaminantes.to_csv('/workspaces/Finarosalina_proyecto_final/data/processed/df_contaminantes_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "487d08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/workspaces/Finarosalina_proyecto_final/data/processed/df_contaminantes_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a4be813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Valores válidos   NaN  % NaN  Ceros  % Ceros  % NaN o 0\n",
      "PUNTO_MUESTREO             6158     0   0.00      0     0.00       0.00\n",
      "ANNO                       6158     0   0.00      0     0.00       0.00\n",
      "MES                        6158     0   0.00      0     0.00       0.00\n",
      "DIA                        6158     0   0.00      0     0.00       0.00\n",
      "FECHA                      6158     0   0.00      0     0.00       0.00\n",
      "NOMBRE_CAPITAL             6158     0   0.00      0     0.00       0.00\n",
      "As                          826  5331  86.57      1     0.02      86.59\n",
      "BaP                         839  5319  86.38      0     0.00      86.38\n",
      "Cd                          826  5331  86.57      1     0.02      86.59\n",
      "Ni                          839  5319  86.38      0     0.00      86.38\n",
      "PM10                        982  5176  84.05      0     0.00      84.05\n",
      "PM2.5                      1006  5152  83.66      0     0.00      83.66\n",
      "Pb                          838  5320  86.39      0     0.00      86.39\n",
      "ICA                        6158     0   0.00      0     0.00       0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Total de filas\n",
    "total = len(df)\n",
    "\n",
    "# Crear resumen por columna\n",
    "resumen = pd.DataFrame({\n",
    "    'Valores válidos': df.apply(lambda col: ((~col.isna()) & (col != 0)).sum()),\n",
    "    'NaN': df.isna().sum(),\n",
    "    'Ceros': (df == 0).sum(),\n",
    "})\n",
    "\n",
    "resumen['% NaN'] = (resumen['NaN'] / total * 100).round(2)\n",
    "resumen['% Ceros'] = (resumen['Ceros'] / total * 100).round(2)\n",
    "resumen['% NaN o 0'] = ((resumen['NaN'] + resumen['Ceros']) / total * 100).round(2)\n",
    "\n",
    "# Reorganizar columnas para claridad\n",
    "resumen = resumen[['Valores válidos', 'NaN', '% NaN', 'Ceros', '% Ceros', '% NaN o 0']]\n",
    "\n",
    "# Mostrar resumen\n",
    "print(resumen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ad161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total=pd.read_csv('/workspaces/Finarosalina_proyecto_final/data/processed/air_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7012a42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>MAGNITUD</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>D01</th>\n",
       "      <th>D02</th>\n",
       "      <th>D03</th>\n",
       "      <th>...</th>\n",
       "      <th>D22</th>\n",
       "      <th>D23</th>\n",
       "      <th>D24</th>\n",
       "      <th>D25</th>\n",
       "      <th>D26</th>\n",
       "      <th>D27</th>\n",
       "      <th>D28</th>\n",
       "      <th>D29</th>\n",
       "      <th>D30</th>\n",
       "      <th>D31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD PUNTO_MUESTREO  ANNO  MES  D01  \\\n",
       "0          3          9         6        19  03009006_19_M  2014    1  NaN   \n",
       "1          3          9         6        19  03009006_19_M  2014    2  NaN   \n",
       "2          3          9         6        19  03009006_19_M  2014    3  0.0   \n",
       "3          3          9         6        19  03009006_19_M  2014    4  NaN   \n",
       "4          3          9         6        19  03009006_19_M  2014    5  NaN   \n",
       "\n",
       "   D02  D03  ...  D22  D23  D24  D25  D26  D27  D28  D29  D30  D31  \n",
       "0  NaN  NaN  ...  0.0  NaN  NaN  NaN  0.0  NaN  NaN  0.0  NaN  0.0  \n",
       "1  NaN  NaN  ...  0.0  NaN  0.0  NaN  NaN  0.0  NaN  NaN  NaN  NaN  \n",
       "2  NaN  0.0  ...  0.0  NaN  0.0  NaN  NaN  0.0  NaN  0.0  NaN  0.0  \n",
       "3  NaN  0.0  ...  NaN  NaN  0.0  NaN  0.0  NaN  NaN  0.0  NaN  NaN  \n",
       "4  0.0  0.0  ...  0.0  0.0  0.0  0.0  NaN  0.0  NaN  0.0  NaN  0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d1eb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ESTACION  NUM_REGISTROS_NO_NULOS\n",
      "0          1                   29096\n",
      "1          2                   12428\n",
      "2          3                    6209\n",
      "3          4                    8926\n",
      "4          5                    7150\n",
      "5          6                    9051\n",
      "6          7                    4511\n",
      "7          8                    3195\n",
      "8          9                    3876\n",
      "9         10                    2187\n",
      "10        11                     282\n",
      "11        12                    2008\n",
      "12        13                     437\n",
      "13        14                     909\n",
      "14        15                    1916\n",
      "15        16                    1085\n",
      "16        17                     800\n",
      "17        18                     335\n",
      "18        19                     163\n",
      "19        20                    1224\n",
      "20        21                     402\n",
      "21        22                     580\n",
      "22        23                     259\n",
      "23        24                     292\n",
      "24        25                     642\n",
      "25        26                     513\n",
      "26        27                     636\n",
      "27        28                    1026\n",
      "28        29                     170\n",
      "29        30                     413\n",
      "30        31                     144\n",
      "31        32                     366\n",
      "32        33                      48\n",
      "33        36                     204\n",
      "34        37                      35\n",
      "35        38                      82\n",
      "36        39                      36\n",
      "37        40                      58\n",
      "38        42                     828\n",
      "39        43                    1754\n",
      "40        44                    1101\n",
      "41        45                    1041\n",
      "42        46                      72\n",
      "43        47                     130\n",
      "44        48                     168\n",
      "45        49                      36\n",
      "46        50                     801\n",
      "47        51                      22\n",
      "48        52                     204\n",
      "49        53                     629\n",
      "50        54                     996\n",
      "51        55                     800\n",
      "52        56                      48\n",
      "53        57                      48\n",
      "54        60                      36\n",
      "55        61                     514\n",
      "56        62                      60\n",
      "57        66                      12\n",
      "58        99                     156\n",
      "59       999                    4996\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suponiendo que ya tienes cargado df_total y las columnas D01 a D31 existen\n",
    "# Paso 1: Seleccionar columnas de días\n",
    "columnas_dias = [col for col in df_total.columns if col.startswith('D')]\n",
    "\n",
    "# Paso 2: Filtrar registros donde al menos un día tenga valor no nulo\n",
    "df_no_nulos = df_total[df_total[columnas_dias].notna().any(axis=1)]\n",
    "\n",
    "# Paso 3: Agrupar por ESTACION y contar los registros no nulos\n",
    "registros_por_estacion = df_no_nulos.groupby('ESTACION').size().reset_index(name='NUM_REGISTROS_NO_NULOS')\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(registros_por_estacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0624999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ESTACION  NUM_REGISTROS\n",
      "0          1          32152\n",
      "1          2          13522\n",
      "2          3           6643\n",
      "3          4           9421\n",
      "4          5           7551\n",
      "5          6           9459\n",
      "6          7           4657\n",
      "7          8           3251\n",
      "8          9           4006\n",
      "9         10           2449\n",
      "10        11            296\n",
      "11        12           2090\n",
      "12        13            441\n",
      "13        14            910\n",
      "14        15           2007\n",
      "15        16           1103\n",
      "16        17            800\n",
      "17        18            339\n",
      "18        19            216\n",
      "19        20           1224\n",
      "20        21            466\n",
      "21        22            596\n",
      "22        23            262\n",
      "23        24            440\n",
      "24        25            648\n",
      "25        26            694\n",
      "26        27            649\n",
      "27        28           1068\n",
      "28        29            180\n",
      "29        30            414\n",
      "30        31            144\n",
      "31        32            370\n",
      "32        33             48\n",
      "33        36            204\n",
      "34        37             36\n",
      "35        38             84\n",
      "36        39             36\n",
      "37        40             58\n",
      "38        42            828\n",
      "39        43           1766\n",
      "40        44           1102\n",
      "41        45           1041\n",
      "42        46             72\n",
      "43        47            144\n",
      "44        48            168\n",
      "45        49             36\n",
      "46        50            853\n",
      "47        51             32\n",
      "48        52            204\n",
      "49        53            672\n",
      "50        54            996\n",
      "51        55            834\n",
      "52        56             48\n",
      "53        57             48\n",
      "54        60             36\n",
      "55        61            518\n",
      "56        62             60\n",
      "57        66             12\n",
      "58        99            156\n",
      "59       999           5009\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Agrupar por ESTACION y contar todos los registros, sin filtrar por valores nulos\n",
    "registros_por_estacion = df_total.groupby('ESTACION').size().reset_index(name='NUM_REGISTROS')\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(registros_por_estacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff15d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Total valores  Nulos  % Nulos\n",
      "D31                    123569  92599    74.94\n",
      "D30                    123569  72915    59.01\n",
      "D29                    123569  71966    58.24\n",
      "D01                    123569  69227    56.02\n",
      "D06                    123569  68581    55.50\n",
      "D24                    123569  67866    54.92\n",
      "D05                    123569  67838    54.90\n",
      "D08                    123569  67692    54.78\n",
      "D28                    123569  67653    54.75\n",
      "D04                    123569  67538    54.66\n",
      "D02                    123569  67484    54.61\n",
      "D25                    123569  67295    54.46\n",
      "D26                    123569  67259    54.43\n",
      "D27                    123569  67150    54.34\n",
      "D03                    123569  66910    54.15\n",
      "D07                    123569  66855    54.10\n",
      "D23                    123569  66768    54.03\n",
      "D18                    123569  66726    54.00\n",
      "D22                    123569  66692    53.97\n",
      "D11                    123569  66564    53.87\n",
      "D09                    123569  66312    53.66\n",
      "D17                    123569  66210    53.58\n",
      "D10                    123569  66078    53.47\n",
      "D16                    123569  66060    53.46\n",
      "D12                    123569  66024    53.43\n",
      "D20                    123569  66015    53.42\n",
      "D19                    123569  65876    53.31\n",
      "D13                    123569  65844    53.29\n",
      "D21                    123569  65737    53.20\n",
      "D14                    123569  65580    53.07\n",
      "D15                    123569  65176    52.74\n",
      "PUNTO_MUESTREO         123569      0     0.00\n",
      "ANNO                   123569      0     0.00\n",
      "ESTACION               123569      0     0.00\n",
      "MUNICIPIO              123569      0     0.00\n",
      "PROVINCIA              123569      0     0.00\n",
      "MAGNITUD               123569      0     0.00\n",
      "MES                    123569      0     0.00\n"
     ]
    }
   ],
   "source": [
    "# Total de filas del DataFrame\n",
    "total_filas = len(df_total)\n",
    "\n",
    "# Calcular estadísticas por columna\n",
    "resumen_nulos = pd.DataFrame({\n",
    "    'Total valores': total_filas,\n",
    "    'Nulos': df_total.isna().sum(),\n",
    "})\n",
    "\n",
    "# Calcular el porcentaje de nulos\n",
    "resumen_nulos['% Nulos'] = (resumen_nulos['Nulos'] / total_filas * 100).round(2)\n",
    "\n",
    "# Ordenar por mayor % de nulos (opcional)\n",
    "resumen_nulos = resumen_nulos.sort_values(by='% Nulos', ascending=False)\n",
    "\n",
    "# Mostrar resultado\n",
    "print(resumen_nulos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d5fe393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'MAGNITUD', 'PUNTO_MUESTREO',\n",
       "       'ANNO', 'MES', 'D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08',\n",
       "       'D09', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'D16', 'D17', 'D18',\n",
       "       'D19', 'D20', 'D21', 'D22', 'D23', 'D24', 'D25', 'D26', 'D27', 'D28',\n",
       "       'D29', 'D30', 'D31'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c9022b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAMINANTE  PROVINCIA  MUNICIPIO  ESTACION  PUNTO_MUESTREO  ANNO  MES  ANNO  \\\n",
      "0                     1         22         1  01022001_10_47  2017    1  2017   \n",
      "1                     1         22         1  01022001_10_47  2017    1  2017   \n",
      "2                     1         22         1  01022001_10_47  2017    1  2017   \n",
      "3                     1         22         1  01022001_10_47  2017    1  2017   \n",
      "4                     1         22         1  01022001_10_47  2017    1  2017   \n",
      "\n",
      "CONTAMINANTE  MES  DIA      FECHA  PM2.5  PM10  As  Pb  BaP  Cd  Ni  \n",
      "0               1    1 2017-01-01    NaN   7.3 NaN NaN  NaN NaN NaN  \n",
      "1               1    2 2017-01-02    NaN   9.1 NaN NaN  NaN NaN NaN  \n",
      "2               1    3 2017-01-03    NaN  16.0 NaN NaN  NaN NaN NaN  \n",
      "3               1    4 2017-01-04    NaN  16.0 NaN NaN  NaN NaN NaN  \n",
      "4               1    5 2017-01-05    NaN  11.0 NaN NaN  NaN NaN NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Asumiendo que tu DataFrame original se llama df_total\n",
    "\n",
    "# Diccionario para mapear magnitudes a contaminantes\n",
    "magnitud_dict = {\n",
    "    9: 'PM2.5',\n",
    "    10: 'PM10',\n",
    "    17: 'As',\n",
    "    19: 'Pb',\n",
    "    27: 'BaP',\n",
    "    28: 'Cd',\n",
    "    62: 'Ni'\n",
    "}\n",
    "\n",
    "# Columnas que NO quieres cambiar\n",
    "columnas_clave = ['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'PUNTO_MUESTREO', 'ANNO', 'MES']\n",
    "\n",
    "# Columnas de días (D01, D02, ..., D31)\n",
    "dias_columnas = [f'D{i:02d}' for i in range(1, 32)]\n",
    "\n",
    "# 1. Melt: pasar columnas D01-D31 a filas (una fila por día)\n",
    "df_long = df_total.melt(\n",
    "    id_vars=columnas_clave + ['MAGNITUD'],\n",
    "    value_vars=dias_columnas,\n",
    "    var_name='DIA',\n",
    "    value_name='VALOR'\n",
    ")\n",
    "\n",
    "# 2. Extraer número de día como entero\n",
    "df_long['DIA'] = df_long['DIA'].str.extract(r'D(\\d+)').astype(int)\n",
    "\n",
    "# 3. Mapear la magnitud a contaminante\n",
    "df_long['CONTAMINANTE'] = df_long['MAGNITUD'].map(magnitud_dict)\n",
    "\n",
    "# 4. Eliminar filas con valores nulos en VALOR o CONTAMINANTE\n",
    "df_long = df_long.dropna(subset=['VALOR', 'CONTAMINANTE'])\n",
    "\n",
    "# 5. Pivotear para tener cada contaminante como columna\n",
    "df_total_fecha = df_long.pivot_table(\n",
    "    index=columnas_clave + ['DIA'],\n",
    "    columns='CONTAMINANTE',\n",
    "    values='VALOR',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# 6. Crear columna FECHA con año, mes y día\n",
    "df_total_fecha['FECHA'] = pd.to_datetime(dict(year=df_total_fecha['ANNO'], month=df_total_fecha['MES'], day=df_total_fecha['DIA']))\n",
    "\n",
    "# 7. Reordenar columnas, sin perder ninguna clave ni contaminante\n",
    "column_order = columnas_clave + ['ANNO', 'MES', 'DIA', 'FECHA'] + list(magnitud_dict.values())\n",
    "# Algunos contaminantes pueden no aparecer, filtramos sólo los que existen\n",
    "column_order = [col for col in column_order if col in df_total_fecha.columns]\n",
    "\n",
    "df_total_fecha = df_total_fecha.reindex(columns=column_order)\n",
    "\n",
    "# Mostrar resultado\n",
    "print(df_total_fecha.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ba77092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD PUNTO_MUESTREO  ANNO  MES  \\\n",
      "21              8         19        45        19  08019045_19_M  2014    8   \n",
      "22              8         19        54        19  08019054_19_M  2014    8   \n",
      "24              8         19         4        19  08019004_19_M  2014    8   \n",
      "25              8         19        42        19  08019042_19_M  2014    8   \n",
      "26              8         19        43        19  08019043_19_M  2014    8   \n",
      "...           ...        ...       ...       ...            ...   ...  ...   \n",
      "121452          8         19        54        28  08019054_28_M  2023   12   \n",
      "122524         50        297        26        28  50297026_28_M  2023    3   \n",
      "122526         50        297        26        28  50297026_28_M  2023    5   \n",
      "123142         15         30        27        27  15030027_27_M  2023    1   \n",
      "123145         15         30        27        27  15030027_27_M  2023    5   \n",
      "\n",
      "             D01       D02       D03  ...       D22       D23       D24  \\\n",
      "21      0.010000  0.010000  0.010000  ...  0.010000  0.010000  0.010000   \n",
      "22      0.010000  0.010000  0.010000  ...  0.010000  0.010000  0.010000   \n",
      "24      0.010000  0.010000  0.010000  ...  0.010000  0.010000  0.010000   \n",
      "25      0.010000  0.010000  0.010000  ...  0.010000  0.010000  0.010000   \n",
      "26      0.010000  0.010000  0.010000  ...  0.010000  0.010000  0.010000   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "121452  0.400000  0.400000  0.400000  ...  0.400000  0.400000  0.400000   \n",
      "122524  0.907161  0.907148  0.907181  ...  0.907140  0.907187  0.907171   \n",
      "122526  0.907169  0.941893  2.466030  ...  0.907199  0.907201  0.907179   \n",
      "123142  0.050000  0.130000  0.050000  ...  0.050000  0.050000  0.050000   \n",
      "123145  0.050000  0.050000  0.050000  ...  0.290000  0.050000  0.320000   \n",
      "\n",
      "             D25       D26       D27       D28       D29       D30       D31  \n",
      "21      0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  \n",
      "22      0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  \n",
      "24      0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  \n",
      "25      0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  \n",
      "26      0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "121452  0.400000  0.400000  0.400000  0.400000  0.400000  0.400000  0.400000  \n",
      "122524  0.907191  0.907171  0.907173  0.907178  0.907191  0.907201  0.907179  \n",
      "122526  0.907220  0.907189  0.907199  0.907194  0.907189  0.907184  0.907189  \n",
      "123142  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  \n",
      "123145  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  \n",
      "\n",
      "[10997 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# Columnas de días\n",
    "dias_columnas = [f'D{i:02d}' for i in range(1, 32)]\n",
    "\n",
    "# Filtrar filas donde NO haya ningún NaN en esas columnas de días\n",
    "df_sin_nan = df_total.dropna(subset=dias_columnas, how='any')\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df_sin_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58025dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntos de muestreo sin ningún valor NaN:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cols_dias = [col for col in df_total.columns if col.startswith('D')]\n",
    "\n",
    "puntos_sin_nan = df_total.groupby('PUNTO_MUESTREO')[cols_dias].apply(lambda x: x.isna().sum().sum() == 0)\n",
    "\n",
    "puntos_sin_nan = puntos_sin_nan[puntos_sin_nan].index.tolist()\n",
    "\n",
    "print(\"Puntos de muestreo sin ningún valor NaN:\")\n",
    "print(puntos_sin_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06ea16b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de puntos con exactamente 1 NaN en todo el mes: 9126\n",
      "Número de puntos con exactamente 2 NaN en todo el mes: 3645\n"
     ]
    }
   ],
   "source": [
    "# Contar NaN por fila\n",
    "num_nan_por_fila = df_total.isna().sum(axis=1)\n",
    "\n",
    "# Filas con exactamente 1 NaN en todo el mes\n",
    "puntos_1_nan = num_nan_por_fila[num_nan_por_fila == 1].index\n",
    "num_puntos_1_nan = len(puntos_1_nan)\n",
    "\n",
    "# Filas con exactamente 2 NaN en todo el mes\n",
    "puntos_2_nan = num_nan_por_fila[num_nan_por_fila == 2].index\n",
    "num_puntos_2_nan = len(puntos_2_nan)\n",
    "\n",
    "print(\"Número de puntos con exactamente 1 NaN en todo el mes:\", num_puntos_1_nan)\n",
    "print(\"Número de puntos con exactamente 2 NaN en todo el mes:\", num_puntos_2_nan)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
