{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e942951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import calendar\n",
    "import unicodedata\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba00663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/Pb_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/As_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/B(a)P_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/Cd_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/PM10_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/Ni_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2014_datos_Diarios/PM2.5_DD_2014.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/Pb_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/Cd_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/As_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/PM2.5_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/Ni_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/B(a)P_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2015_datos_Diarios/PM10_DD_2015.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/As_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/B(a)P_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/PM10_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/Cd_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/Ni_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/Pb_DD_2016.xlsx\n",
      "Leyendo Excel: /workspaces/Finarosalina_proyecto_final/data/raw/2014_2016_Datos_diarios_excel/2016_datos_Diarios/PM25_DD_2016.xlsx\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/Pb_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/Ni_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/BaP_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/Cd_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/PM2.5_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/As_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2013_Datos_diarios/PM10_2013_DD.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/PM10_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/B(a)P_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/PM2.5_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/As_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/Pb_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/Cd_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2017_Datos_diarios/Ni_DD_2017.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/B(a)P_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/Cd_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/Ni_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/PM2.5_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/As_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/PM10_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2018_Datos_diarios/Pb_DD_2018.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/PM25_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/As_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/Cd_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/PM10_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/C6H6_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/Pb_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/BaP_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2019_datos_diarios/Ni_DD_2019.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/B(a)P_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/Pb_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/PM10_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/PM2.5_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/Ni_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/Cd_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/As_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2020_Datos_diarios/C6H6_DD_2020.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/PM25_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/BaP_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/As_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/Cd_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/PM10_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/Ni_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2021_Datos_diarios/Pb_DD_2021.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/Ni_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/PM2.5_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/B(a)P_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/Cd_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/PM10_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/C6H6_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/Pb_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2022_Datos_diarios/As_DD_2022.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/C6H6_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/PM2.5_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/PM10_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/As_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/Pb_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/Ni_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/Cd_DD_2023.csv\n",
      "Leyendo CSV: /workspaces/Finarosalina_proyecto_final/data/raw/2023_Datos_diarios/B(a)P_DD_2023.csv\n",
      "Archivo combinado guardado en /workspaces/Finarosalina_proyecto_final/data/air_data.csv\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/workspaces/Finarosalina_proyecto_final/data/raw\"\n",
    "dfs = []\n",
    "\n",
    "# Función para extraer año de la carpeta (ejemplo: \"2013_Datos_diarios\" -> 2013)\n",
    "def extraer_anno(nombre_carpeta):\n",
    "    import re\n",
    "    match = re.search(r'(\\d{4})', nombre_carpeta)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# 1. Leer Excel (2014-2016)\n",
    "for year_folder in ['2014_datos_Diarios', '2015_datos_Diarios', '2016_datos_Diarios']:\n",
    "    folder_path = os.path.join(base_path, \"2014_2016_Datos_diarios_excel\", year_folder)\n",
    "    anno = extraer_anno(year_folder)\n",
    "    excel_files = glob(os.path.join(folder_path, \"*.xlsx\")) + glob(os.path.join(folder_path, \"*.xls\"))\n",
    "    for file in excel_files:\n",
    "        print(f\"Leyendo Excel: {file}\")\n",
    "        df = pd.read_excel(file)\n",
    "        if 'ANNO' not in df.columns:\n",
    "            df['ANNO'] = anno\n",
    "        dfs.append(df)\n",
    "\n",
    "# 2. Leer CSVs (otros años)\n",
    "years_with_csv = [\n",
    "    \"2013_Datos_diarios\", \"2017_Datos_diarios\", \"2018_Datos_diarios\",\n",
    "    \"2019_datos_diarios\", \"2020_Datos_diarios\", \"2021_Datos_diarios\",\n",
    "    \"2022_Datos_diarios\", \"2023_Datos_diarios\"\n",
    "]\n",
    "\n",
    "for year_folder in years_with_csv:\n",
    "    folder_path = os.path.join(base_path, year_folder)\n",
    "    anno = extraer_anno(year_folder)\n",
    "    csv_files = glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    for file in csv_files:\n",
    "        print(f\"Leyendo CSV: {file}\")\n",
    "        df = pd.read_csv(file, sep=';', encoding='utf-8')\n",
    "        if 'ANNO' not in df.columns:\n",
    "            df['ANNO'] = anno\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenar y guardar\n",
    "air_data = pd.concat(dfs, ignore_index=True)\n",
    "output_path = \"/workspaces/Finarosalina_proyecto_final/data/air_data.csv\"\n",
    "air_data.to_csv(output_path, index=False, sep=';')\n",
    "print(f\"Archivo combinado guardado en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fe4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspaces/Finarosalina_proyecto_final/data/processed/air_data.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5813daa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>MAGNITUD</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>D01</th>\n",
       "      <th>D02</th>\n",
       "      <th>D03</th>\n",
       "      <th>...</th>\n",
       "      <th>D22</th>\n",
       "      <th>D23</th>\n",
       "      <th>D24</th>\n",
       "      <th>D25</th>\n",
       "      <th>D26</th>\n",
       "      <th>D27</th>\n",
       "      <th>D28</th>\n",
       "      <th>D29</th>\n",
       "      <th>D30</th>\n",
       "      <th>D31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>03009006_19_M</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD PUNTO_MUESTREO  ANNO  MES  D01  \\\n",
       "0          3          9         6        19  03009006_19_M  2014    1  NaN   \n",
       "1          3          9         6        19  03009006_19_M  2014    2  NaN   \n",
       "2          3          9         6        19  03009006_19_M  2014    3  0.0   \n",
       "3          3          9         6        19  03009006_19_M  2014    4  NaN   \n",
       "4          3          9         6        19  03009006_19_M  2014    5  NaN   \n",
       "\n",
       "   D02  D03  ...  D22  D23  D24  D25  D26  D27  D28  D29  D30  D31  \n",
       "0  NaN  NaN  ...  0.0  NaN  NaN  NaN  0.0  NaN  NaN  0.0  NaN  0.0  \n",
       "1  NaN  NaN  ...  0.0  NaN  0.0  NaN  NaN  0.0  NaN  NaN  NaN  NaN  \n",
       "2  NaN  0.0  ...  0.0  NaN  0.0  NaN  NaN  0.0  NaN  0.0  NaN  0.0  \n",
       "3  NaN  0.0  ...  NaN  NaN  0.0  NaN  0.0  NaN  NaN  0.0  NaN  NaN  \n",
       "4  0.0  0.0  ...  0.0  0.0  0.0  0.0  NaN  0.0  NaN  0.0  NaN  0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7468e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123569, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c9c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROVINCIA             0\n",
      "MUNICIPIO             0\n",
      "ESTACION              0\n",
      "MAGNITUD              0\n",
      "PUNTO_MUESTREO        0\n",
      "ANNO                  0\n",
      "MES                   0\n",
      "D01               69227\n",
      "D02               67484\n",
      "D03               66910\n",
      "D04               67538\n",
      "D05               67838\n",
      "D06               68581\n",
      "D07               66855\n",
      "D08               67692\n",
      "D09               66312\n",
      "D10               66078\n",
      "D11               66564\n",
      "D12               66024\n",
      "D13               65844\n",
      "D14               65580\n",
      "D15               65176\n",
      "D16               66060\n",
      "D17               66210\n",
      "D18               66726\n",
      "D19               65876\n",
      "D20               66015\n",
      "D21               65737\n",
      "D22               66692\n",
      "D23               66768\n",
      "D24               67866\n",
      "D25               67295\n",
      "D26               67259\n",
      "D27               67150\n",
      "D28               67653\n",
      "D29               71966\n",
      "D30               72915\n",
      "D31               92599\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_por_columna = df.isna().sum()\n",
    "print(nan_por_columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc1f1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'MAGNITUD', 'PUNTO_MUESTREO',\n",
       "       'ANNO', 'MES', 'D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08',\n",
       "       'D09', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'D16', 'D17', 'D18',\n",
       "       'D19', 'D20', 'D21', 'D22', 'D23', 'D24', 'D25', 'D26', 'D27', 'D28',\n",
       "       'D29', 'D30', 'D31'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31cafb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en columnas ANNO, MES, DIA antes de crear la columna FECHA:\n",
      "ANNO    0\n",
      "MES     0\n",
      "DIA     0\n",
      "dtype: int64\n",
      "   PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD PUNTO_MUESTREO  ANNO  MES  DIA  \\\n",
      "0          3          9         6        19  03009006_19_M  2014    1    1   \n",
      "1          3          9         6        19  03009006_19_M  2014    2    1   \n",
      "2          3          9         6        19  03009006_19_M  2014    3    1   \n",
      "3          3          9         6        19  03009006_19_M  2014    4    1   \n",
      "4          3          9         6        19  03009006_19_M  2014    5    1   \n",
      "\n",
      "   VALOR      FECHA  \n",
      "0    NaN 2014-01-01  \n",
      "1    NaN 2014-02-01  \n",
      "2    0.0 2014-03-01  \n",
      "3    NaN 2014-04-01  \n",
      "4    NaN 2014-05-01  \n"
     ]
    }
   ],
   "source": [
    "# Función para validar la fecha\n",
    "def es_fecha_valida(anno, mes, dia):\n",
    "    if mes < 1 or mes > 12 or dia < 1:\n",
    "        return False\n",
    "    ultimo_dia = calendar.monthrange(anno, mes)[1]  # Obtiene el último día del mes\n",
    "    return dia <= ultimo_dia  # Comprueba si el día es válido\n",
    "\n",
    "# Primero, seleccionamos las columnas de días\n",
    "dias_columnas = [f'D{i:02d}' for i in range(1, 32)]  # ['D01', 'D02', ..., 'D31']\n",
    "\n",
    "# Aplanamos el DataFrame para que cada fila represente un día\n",
    "df = df.melt(id_vars=['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'MAGNITUD', 'PUNTO_MUESTREO', 'ANNO', 'MES'],\n",
    "             value_vars=dias_columnas,\n",
    "             var_name='DIA', value_name='VALOR')\n",
    "\n",
    "# Extraer el número de día de la columna 'DIA'\n",
    "df['DIA'] = df['DIA'].str.extract(r'D(\\d+)').astype(int)\n",
    "\n",
    "# Aplicamos la validación de la fecha para cada fila\n",
    "df['fecha_valida'] = df.apply(lambda row: es_fecha_valida(row['ANNO'], row['MES'], row['DIA']), axis=1)\n",
    "\n",
    "# Filtramos las filas que tengan fecha válida\n",
    "df = df[df['fecha_valida']]\n",
    "\n",
    "# Verificar si alguna columna tiene valores nulos o vacíos antes de convertir a fecha\n",
    "print(\"Valores nulos en columnas ANNO, MES, DIA antes de crear la columna FECHA:\")\n",
    "print(df[['ANNO', 'MES', 'DIA']].isna().sum())\n",
    "\n",
    "# Filtrar filas con valores nulos en ANNO, MES o DIA\n",
    "df = df.dropna(subset=['ANNO', 'MES', 'DIA'])\n",
    "\n",
    "# Crear la columna FECHA usando las columnas 'ANNO', 'MES', y 'DIA'\n",
    "df['FECHA'] = pd.to_datetime(df[['ANNO', 'MES', 'DIA']].astype(str).agg('-'.join, axis=1))\n",
    "\n",
    "# Ya podemos eliminar la columna auxiliar 'fecha_valida'\n",
    "df.drop(columns=['fecha_valida'], inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame final\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "419f442f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3760021, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88ca12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# que sea string\n",
    "df['PUNTO_MUESTREO'] = df['PUNTO_MUESTREO'].astype(str)\n",
    "\n",
    "# Extraer la clave: primeros 5 dígitos (provincia + municipio)\n",
    "df['PUNTO_MUESTREO'] = df['PUNTO_MUESTREO'].astype(str)\n",
    "\n",
    "# Extraer la clave como los primeros 5 dígitos del campo\n",
    "df['CLAVE'] = df['PUNTO_MUESTREO'].str.extract(r'(\\d{5})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cca46b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "\n",
    "# === 1. Cargar diccionario de municipios desde Excel ===\n",
    "df_dic = pd.read_excel(\n",
    "    '/workspaces/Finarosalina_proyecto_final/data/raw/diccionario23.xlsx',\n",
    "    skiprows=1,  # Saltar primera fila de paja\n",
    "    dtype={'CPRO': str, 'CMUN': str}  # Asegurar lectura como texto\n",
    ")\n",
    "\n",
    "# Asegurar formato correcto de códigos\n",
    "df_dic['CPRO'] = df_dic['CPRO'].str.zfill(2)\n",
    "df_dic['CMUN'] = df_dic['CMUN'].str.zfill(3)\n",
    "df_dic['CLAVE'] = df_dic['CPRO'] + df_dic['CMUN']\n",
    "\n",
    "# Normalizar nombres para que no tengan tildes ni caracteres especiales\n",
    "df_dic['NOMBRE_NORMALIZADO'] = df_dic['NOMBRE '].apply(lambda x: unidecode.unidecode(str(x)).strip())\n",
    "\n",
    "# === 2. Diccionario de capitales de provincia ===\n",
    "capitales_mun_dict = {\n",
    "    '0159': 'Vitoria Gasteiz', '02003': 'Albacete', '0314': 'Alacant Alicante', '0413': 'Almeria', '0519': 'Avila',\n",
    "    '15': 'Badajoz', '0740': 'Palma', '19': 'Barcelona', '0959': 'Burgos', '37': 'Caceres',\n",
    "    '12': 'Cadiz', '1240': 'Castello de la Plana', '13': 'Ciudad Real', '14': 'Cordoba',\n",
    "    '15': 'Coruna', '16': 'Cuenca', '17': 'Girona', '18': 'Granada', '19': 'Guadalajara',\n",
    "    '20': 'San Sebastian', '21': 'Huelva', '22': 'Huesca', '23': 'Jaen', '24': 'Leon',\n",
    "    '25': 'Lleida', '26': 'Logrono', '27': 'Lugo', '28': 'Madrid', '29': 'Malaga',\n",
    "    '30': 'Murcia', '31': 'Pamplona', '32': 'Ourense', '33': 'Oviedo', '34': 'Palencia',\n",
    "    '35': 'Las Palmas', '36': 'Pontevedra', '37': 'Salamanca', '38': 'Santa Cruz de Tenerife',\n",
    "    '39': 'Santander', '40': 'Segovia', '41': 'Sevilla', '42': 'Soria', '43': 'Tarragona',\n",
    "    '44': 'Teruel', '45': 'Toledo', '46': 'Valencia', '47': 'Valladolid', '48': 'Bilbao',\n",
    "    '49': 'Zamora', '50': 'Zaragoza', '51': 'Ceuta', '52': 'Melilla'\n",
    "}\n",
    "\n",
    "# Crear diccionario final: claves válidas del Excel que estén en el dict de capitales\n",
    "diccionario_capitales = {\n",
    "    clave: capitales_mun_dict[clave]\n",
    "    for clave in df_dic['CLAVE']\n",
    "    if clave in capitales_mun_dict\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c04f6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_capitales = df[df['CLAVE'].isin(diccionario_capitales.keys())].copy()\n",
    "\n",
    "# Añadir nombre de la capital\n",
    "\n",
    "df['NOMBRE_CAPITAL'] = df['CLAVE'].map(diccionario_capitales)\n",
    "df_capitales = df[df['NOMBRE_CAPITAL'].notna()].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc3e7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capitales = df[df['PUNTO_MUESTREO'].str[:5].isin(diccionario_capitales.keys())].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89eebe3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16505, 12)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_capitales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bcdd506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df_capitales: (16505, 12)\n",
      "\n",
      "Valores nulos por columna:\n",
      "PROVINCIA             0\n",
      "MUNICIPIO             0\n",
      "ESTACION              0\n",
      "MAGNITUD              0\n",
      "PUNTO_MUESTREO        0\n",
      "ANNO                  0\n",
      "MES                   0\n",
      "DIA                   0\n",
      "VALOR             10347\n",
      "FECHA                 0\n",
      "CLAVE                 0\n",
      "NOMBRE_CAPITAL        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ver la forma (filas, columnas)\n",
    "print(\"Shape df_capitales:\", df_capitales.shape)\n",
    "\n",
    "# Cantidad de valores nulos por columna\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df_capitales.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d4ae7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>NOMBRE_CAPITAL</th>\n",
       "      <th>As</th>\n",
       "      <th>BaP</th>\n",
       "      <th>Cd</th>\n",
       "      <th>Ni</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>Pb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROVINCIA  MUNICIPIO  ESTACION  PUNTO_MUESTREO  ANNO  MES  DIA      FECHA  \\\n",
       "0          2          3         1  02003001_10_49  2017    1    1 2017-01-01   \n",
       "1          2          3         1  02003001_10_49  2017    1    2 2017-01-02   \n",
       "2          2          3         1  02003001_10_49  2017    1    3 2017-01-03   \n",
       "3          2          3         1  02003001_10_49  2017    1    6 2017-01-06   \n",
       "4          2          3         1  02003001_10_49  2017    1    7 2017-01-07   \n",
       "\n",
       "  NOMBRE_CAPITAL  As  BaP  Cd  Ni  PM10  PM2.5  Pb  \n",
       "0       Albacete NaN  NaN NaN NaN  27.0    NaN NaN  \n",
       "1       Albacete NaN  NaN NaN NaN  21.0    NaN NaN  \n",
       "2       Albacete NaN  NaN NaN NaN  32.0    NaN NaN  \n",
       "3       Albacete NaN  NaN NaN NaN  25.0    NaN NaN  \n",
       "4       Albacete NaN  NaN NaN NaN  24.0    NaN NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diccionario de nombres contaminantes\n",
    "magnitud_dict = {\n",
    "    9: 'PM2.5',\n",
    "    10: 'PM10',\n",
    "    17: 'As',\n",
    "    19: 'Pb',\n",
    "    27: 'BaP',\n",
    "    28: 'Cd',\n",
    "    62: 'Ni'\n",
    "}\n",
    "\n",
    "# Mapear nombre del contaminante\n",
    "df_capitales['MAGNITUD_NOMBRE'] = df_capitales['MAGNITUD'].map(magnitud_dict)\n",
    "\n",
    "# Filtrar filas que tienen valor y contaminante reconocido\n",
    "df_filtrado = df_capitales[\n",
    "    df_capitales['VALOR'].notnull() &\n",
    "    df_capitales['MAGNITUD_NOMBRE'].notnull()\n",
    "]\n",
    "\n",
    "# Pivotar para tener cada contaminante como columna\n",
    "df_contaminantes = df_filtrado.pivot_table(\n",
    "    index=['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'PUNTO_MUESTREO', 'ANNO', 'MES', 'DIA', 'FECHA', 'NOMBRE_CAPITAL'],\n",
    "    columns='MAGNITUD_NOMBRE',\n",
    "    values='VALOR',\n",
    "    aggfunc='first'  # O 'mean' si hay múltiples valores\n",
    ").reset_index()\n",
    "\n",
    "# Limpiar el nombre del índice de columnas creado por pivot_table\n",
    "df_contaminantes.columns.name = None\n",
    "\n",
    "df_contaminantes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8122ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la columna punto_muestreo contiene codigo provincia(2)+codigo municipio(3)+estacion(3)\n",
    "df_contaminantes = df_contaminantes.drop(columns=['PROVINCIA', 'MUNICIPIO', 'ESTACION'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1484710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>NOMBRE_CAPITAL</th>\n",
       "      <th>As</th>\n",
       "      <th>BaP</th>\n",
       "      <th>Cd</th>\n",
       "      <th>Ni</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>Pb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PUNTO_MUESTREO  ANNO  MES  DIA      FECHA NOMBRE_CAPITAL  As  BaP  Cd  Ni  \\\n",
       "0  02003001_10_49  2017    1    1 2017-01-01       Albacete NaN  NaN NaN NaN   \n",
       "1  02003001_10_49  2017    1    2 2017-01-02       Albacete NaN  NaN NaN NaN   \n",
       "2  02003001_10_49  2017    1    3 2017-01-03       Albacete NaN  NaN NaN NaN   \n",
       "3  02003001_10_49  2017    1    6 2017-01-06       Albacete NaN  NaN NaN NaN   \n",
       "4  02003001_10_49  2017    1    7 2017-01-07       Albacete NaN  NaN NaN NaN   \n",
       "\n",
       "   PM10  PM2.5  Pb  \n",
       "0  27.0    NaN NaN  \n",
       "1  21.0    NaN NaN  \n",
       "2  32.0    NaN NaN  \n",
       "3  25.0    NaN NaN  \n",
       "4  24.0    NaN NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contaminantes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f2a146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6158, 13)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contaminantes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41261afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CCAA                            NOMBRE_ZONA CODIGO_ZONA          TIPO  \\\n",
      "0  ANDALUCÍA  ZONA INDUSTRIAL DE BAHIA DE ALGECIRAS      ES0104          zona   \n",
      "1  ANDALUCÍA              ZONA INDUSTRIAL DE BAILEN      ES0108          zona   \n",
      "2  ANDALUCÍA                                CORDOBA      ES0111  aglomeracion   \n",
      "3  ANDALUCÍA          ZONA INDUSTRIAL DE CARBONERAS      ES0116          zona   \n",
      "4  ANDALUCÍA           GRANADA Y AREA METROPOLITANA      ES0118  aglomeracion   \n",
      "\n",
      "     AREA  POBLACION  SO2  SO2_E  NO2  NOX_V  ...  PM25   PB  C6H6   CO   O3  \\\n",
      "0  583.50     242508  1.0    NaN  1.0    NaN  ...   1.0  1.0   1.0  1.0  1.0   \n",
      "1  121.01      17498  1.0    NaN  1.0    NaN  ...   1.0  1.0   1.0  1.0  1.0   \n",
      "2  141.03     322071  1.0    NaN  1.0    NaN  ...   1.0  1.0   1.0  1.0  1.0   \n",
      "3  695.01      39641  1.0    NaN  1.0    NaN  ...   1.0  1.0   1.0  1.0  1.0   \n",
      "4  560.74     500735  1.0    NaN  1.0    NaN  ...   1.0  1.0   1.0  1.0  1.0   \n",
      "\n",
      "   'AS'   CD   NI  BAP  O3_V  \n",
      "0   1.0  1.0  1.0  1.0   1.0  \n",
      "1   1.0  1.0  1.0  1.0   NaN  \n",
      "2   1.0  1.0  1.0  1.0   1.0  \n",
      "3   1.0  1.0  1.0  1.0   1.0  \n",
      "4   1.0  1.0  1.0  1.0   1.0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Index(['CCAA', 'NOMBRE_ZONA', 'CODIGO_ZONA', 'TIPO', 'AREA', 'POBLACION',\n",
      "       'SO2', 'SO2_E', 'NO2', 'NOX_V', 'PM10', 'PM25', 'PB', 'C6H6', 'CO',\n",
      "       'O3', ''AS'', 'CD', 'NI', 'BAP', 'O3_V'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# https://www.miteco.gob.es/es/calidad-y-evaluacion-ambiental/temas/atmosfera-y-calidad-del-aire/evaluacion-y-datos-de-calidad-del-aire/datos.html\n",
    "# hemos encontrado un plan de muestreo segun el que no se tienen que medir todos los contaminantes en todas las zonas\n",
    "\n",
    "# 1. Cargar el plan de medición\n",
    "df_plan_medicion = pd.read_excel('/workspaces/Finarosalina_proyecto_final/data/raw/plan_medicion_2022_por_zona.xlsx')\n",
    "\n",
    "# 2. Ver las primeras filas para entender su estructura\n",
    "print(df_plan_medicion.head())\n",
    "\n",
    "# 3. Mostrar columnas para conocer las variables que miden (por ejemplo SO2, NO2, PM10...)\n",
    "print(df_plan_medicion.columns)\n",
    "\n",
    "# no podemos relacionarlo con nuestro data set pq no hay codigos unicos que lo hagan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af0e7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_ica(row):\n",
    "    # Umbrales\n",
    "    umbrales_bajos = {'As': 1, 'BaP': 0.1, 'Cd': 0.5, 'Ni': 1, 'PM10': 20, 'PM2.5': 10, 'Pb': 0.5}\n",
    "    umbrales_altos = {'As': 5, 'BaP': 0.5, 'Cd': 1.0, 'Ni': 5, 'PM10': 50, 'PM2.5': 25, 'Pb': 1.5}\n",
    "\n",
    "    calidad = 1  # Empezamos en buena calidad\n",
    "\n",
    "    for c in umbrales_bajos.keys():\n",
    "        valor = row.get(c, float('nan'))\n",
    "        if pd.isna(valor):\n",
    "            continue  # ignoramos valores NaN\n",
    "\n",
    "        if valor > umbrales_altos[c]:\n",
    "            return 3  # Mala calidad, primer umbral alto superado\n",
    "        elif valor > umbrales_bajos[c]:\n",
    "            calidad = max(calidad, 2)  # Calidad moderada si supera umbral bajo\n",
    "\n",
    "    return calidad\n",
    "\n",
    "# Aplicar al dataframe\n",
    "df_contaminantes['ICA'] = df_contaminantes.apply(calcular_ica, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c452001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>NOMBRE_CAPITAL</th>\n",
       "      <th>As</th>\n",
       "      <th>BaP</th>\n",
       "      <th>Cd</th>\n",
       "      <th>Ni</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>Pb</th>\n",
       "      <th>ICA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02003001_10_49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Albacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PUNTO_MUESTREO  ANNO  MES  DIA      FECHA NOMBRE_CAPITAL  As  BaP  Cd  Ni  \\\n",
       "0  02003001_10_49  2017    1    1 2017-01-01       Albacete NaN  NaN NaN NaN   \n",
       "1  02003001_10_49  2017    1    2 2017-01-02       Albacete NaN  NaN NaN NaN   \n",
       "2  02003001_10_49  2017    1    3 2017-01-03       Albacete NaN  NaN NaN NaN   \n",
       "3  02003001_10_49  2017    1    6 2017-01-06       Albacete NaN  NaN NaN NaN   \n",
       "4  02003001_10_49  2017    1    7 2017-01-07       Albacete NaN  NaN NaN NaN   \n",
       "\n",
       "   PM10  PM2.5  Pb  ICA  \n",
       "0  27.0    NaN NaN    2  \n",
       "1  21.0    NaN NaN    2  \n",
       "2  32.0    NaN NaN    2  \n",
       "3  25.0    NaN NaN    2  \n",
       "4  24.0    NaN NaN    2  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contaminantes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2507f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contaminantes.to_csv('/workspaces/Finarosalina_proyecto_final/data/processed/df_contaminantes_processed.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
